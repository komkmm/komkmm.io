# NN
> A class of function(including linear function, non-linear function, etc..) stacking hierarchical simpler functions in order to make more complex  non-linear functions.
eg) 2-layer Neural Network
>>![equation](https://latex.codecogs.com/gif.latex?f%20%3D%20W_%7B2%7Dmax%280%2C%20W_%7B1%7Dx%29)


# CNN(Convolutional Neural Network)
  * Input -> Convolution layer -> ReLU -> Pooling -> Convolution layer -> Relu -> Pooling ... -> FC -> output

> Convolution layer
  * Convolution layer에 Filter 적용시 size가 급격히 작아짐으로 인해 정보 손실이 커지게 될 수 있음. 이를 방지하기 위해
  padding을 통해서 급격한 size 축소를 막음으로써 정보 손실을 줄일 수 있음
  * Convolution layer output = (N - F) / stride + 1
  
>Pooling layer
>>*makes the representations smaller and more manageable
>>*operates over each activation map independently

  * Pooling할 때의 Filter는 activation map을 extract할 때 적용되는 Filter와 다름. 전자는 fixed, 후자는 runnable한 Filter임
  전자를 Filter가 아닌 Kernel로 지칭하기도 함.


# RNN(Recurrent Neural Network)
  * Language와 같은 Sequence data에서 NN, CNN을 통해서 처리할 수 없기 때문에 등장
  (Time step에 따라서 이전의 result가 다음 result에 영향을 미칠 수 있어야 하기 때문)
  	
   
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE3MDQ1Nzg5MDQsLTEwNjgwOTYyNjUsMT
A2MTg2MDc5LDgwNzIzMjUyOSwxNjAwMzUwMTM2LDcxOTUxMDY3
NCw4NDcyMzQ0MzAsLTIxMDU1MzQ0MDEsLTgxNDEzNjgyNiwyMT
I3OTMwMDM2XX0=
-->