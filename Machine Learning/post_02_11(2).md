# NN
> A class of function(including linear function, non-linear function, etc..) stacking hierarchical simpler functions in order to make more complex  non-linear functions.
eg) 2-layer Neural Network
>>![equation](https://latex.codecogs.com/gif.latex?f%20%3D%20W_%7B2%7Dmax%280%2C%20W_%7B1%7Dx%29)


# CNN(Convolutional Neural Network)
  * Input -> Convolution layer -> ReLU -> Pooling -> Convolution layer -> Relu -> Pooling ... -> FC -> output

> Convolution layer
  * Convolution layer에 Filter 적용시 size가 급격히 작아짐으로 인해 정보 손실이 커지게 될 수 있음. 이를 방지하기 위해
  padding을 통해서 급격한 size 축소를 막음으로써 정보 손실을 줄일 수 있음
  * Convolution layer output = (N - F) / stride + 1
  
>Pooling layer
>>*makes the representations smaller and more manageable
>>*operates over each activation map independently

  * Pooling할 때의 Filter는 activation map을 extract할 때 적용되는 Filter와 다름. 전자는 fixed, 후자는 runnable한 Filter임
  전자를 Filter가 아닌 Kernel로 지칭하기도 함.
  * Pooling시에는 padding을 하지 않음. 이유는 Downsampling이 
  목적이며, corner 값이 간과되는 경우도 없기 때문
  
  * Q: Pooling시 겹치치 않게 하는 것이 일반적인지? 
     A: Yes. Downsampling이 목적이기 때문에
  * Q: Max Pooling이 Average Pooling보다 좋은 이유?
	 A: 직관적으로 어떤 signal에 대해서 얼마나 활성화 되었는지를 판단하기 위해서는 Max값을 활용하는 것이 더 유용
  * Q: Pooling보다 Stride가 동일한 것 아닌지?
     A: 실제로 Pooling 대신에 Stride를 사용하는 사람도 많다.

> Regularization
>> Train data가 overfitting 하지 않도록 만들어 train/test error의 gap을 줄이는 것 

	* Dropout
	* Batch Normalization -> 일반적으로 많이 사용
	* Data Augmentation
	* DropConnect
	* Fractional Max Pooling
	* Stochastic Depth

# CNN Architectures
## AlexNet
> 2012, LeNet과 유사, Conv layers 5, FC layers 2

## VGGNet
> 2014, layers 16(VGG16) ~ 19(VGG19), AlexNet에 비해서 크기가 작은 filter를 사용(filter 크기를 낮추고 depth를 늘림)

## GoogLeNet
> 2014, layers 22, No FC-layers(parameter를 줄이기 위해), Inception module 사용

## ResNet
> 2015, 

# Transfer Learning
> Train Data가 충분히 많지 않을 때, 기존에 학습된 모델을 가져와서 FC 층만 초기화하여 Train 시키는 것


# RNN(Recurrent Neural Network)
> ![equation](https://latex.codecogs.com/gif.latex?%5C%5Ch_%7Bt%7D%20%3D%20f_%7BW%7D%28h_%7Bt-1%7D%2Cx_%7Bt%7D%29%20%5C%5Ch_%7Bt%7D%20%3A%20new%5C%2Cstate%20%5C%5Cf_%7BW%7D%20%3A%20some%5C%2Cfunction%5C%2Cwith%5C%2Cparameters%5C%2CW%20%5C%5Ch_%7Bt-1%7D%20%3A%20old%5C%2Cstate%20%5C%5Cx_%7Bt%7D%20%3A%20input%5C%2Cvector%5C%2Cat%5C%2Csome%5C%2Ctime%5C%2Cstep)  
> Vanilla Recurrent Neural Network
> ![equation](https://latex.codecogs.com/gif.latex?%5C%5Ch_%7Bt%7D%20%3D%20tanh%28W_%7Bhh%7Dh_%7Bt-1%7D&plus;W_%7Bxh%7Dx_%7Bt%7D%29%20%5C%5Cy_%7Bt%7D%20%3D%20W_%7Bhy%7Dh_%7Bt%7D)
* Language와 같은 Sequence data에서 NN, CNN을 통해서 처리할 수 없기 때문에 등장
  (Time step에 따라서 이전의 result가 다음 result에 영향을 미칠 수 있어야 하기 때문)
  * one to many : Image Captioning(Image -> Seq of words)
  * many to one : Sentiment Classification(Seq of words -> sentiment)
  * many to many : Machine Translation(Seq of words -> seq of words)
								Video classification on frame level
  ## Vanishing Gradient Descent
  > RNN이 이전 state를 input으로 받기 때문에 backpropagation할 때, Weight이
  지속적으로 곱해지게 됨. 결과적으로 h0 같은 경우 state의 갯수만큼 Weight이 곱해지게 되고 Weight이 1보다 크면 Exploding, 1보다 작으면 Vanishing이 일어남
  * Exploding gradient : gradient clipping 사용. gradient가 너무 클 경우 threshold를 설정하여 강제로 조정 
  * Vanishing gradient : 해결을 위해 LSTM(Long Short Term Memory) 등장
 
 ## LSTM(Long Short Term Memory)
 > Exploding/Vanishing gradient를 완화하기 위한 RNN Architecture
 >  
 > ![equation](https://latex.codecogs.com/gif.latex?%5C%5C%5Cbegin%7BBmatrix%7D%20i%20%5C%5C%20f%20%5C%5C%20o%20%5C%5C%20g%20%5Cend%7BBmatrix%7D%20%3D%20%5Cbegin%7BBmatrix%7D%20%5Csigma%20%5C%5C%20%5Csigma%20%5C%5C%20%5Csigma%20%5C%5C%20tanh%20%5Cend%7BBmatrix%7D%20W%20%5Cbegin%7Bpmatrix%7D%20h_%7Bt-1%7D%20%5C%5C%20x_%7Bt%7D%20%5Cend%7Bpmatrix%7D%20%5C%5C%20%5C%5Cc_%7Bt%7D%20%3D%20f%20%5Codot%20c_%7Bt-1%7D%20&plus;%20i%20%5Codot%20g%20%5C%5Ch_%7Bt%7D%20%3D%20o%20%5Codot%20tanh%28c_%7Bt%7D%29)

## GRU

# Computer Vision Task

## Semantic Segmentation
> 모든 fixel에 대해서 Category를 구분

### 1) Sliding Window
> Input image를 매우 작은 영역으로 쪼개서 model simulation
* Cost가 너무 커서 좋은 방법이 아님

### 2) Fully Convolutional Network
> FC가 없는 Conv Layer만 쌓아올려서 Train
* 모든 fixel에 대해서 classification을 하는 것과 마찬가지임
   하지만 Train data를 만들기 위해서 모든 fixel에 labeling을 해야한다는 점에서 Cost가 매우 큼
* Input Image의 spatial size를 유지시켜야 하므로 Cost가 큼. 이를 해결하기 위해 Network안에서 downsampling + upsampling을 반복적으로 시행
#### cf) upsampling(unpooling)
* Nearest Neighbor
> ![equation](https://latex.codecogs.com/gif.latex?%5Cbegin%7Bbmatrix%7D%201%20%26%202%5C%5C%203%20%26%204%20%5Cend%7Bbmatrix%7D%20%5Crightarrow%20%5Cbegin%7Bbmatrix%7D%201%20%26%201%20%26%202%20%26%202%5C%5C%201%20%26%201%20%26%202%20%26%202%5C%5C%203%20%26%203%20%26%204%20%26%204%5C%5C%203%20%26%203%20%26%204%20%26%204%20%5Cend%7Bbmatrix%7D)
* Bed of Nails
> ![equation](https://latex.codecogs.com/gif.latex?%5Cbegin%7Bbmatrix%7D%201%20%26%202%5C%5C%203%20%26%204%20%5Cend%7Bbmatrix%7D%20%5Crightarrow%20%5Cbegin%7Bbmatrix%7D%201%20%26%200%20%26%202%20%26%200%5C%5C%200%20%26%200%20%26%200%20%26%200%5C%5C%203%20%26%200%20%26%204%20%26%200%5C%5C%200%20%26%200%20%26%200%20%26%200%20%5Cend%7Bbmatrix%7D)
* Max unpooling
> Max pooling시에 선택된 위치로 unpooling 시키는 것
> 
> ![equation](https://latex.codecogs.com/gif.latex?%5Cbegin%7Bbmatrix%7D%201%20%26%202%5C%5C%203%20%26%204%20%5Cend%7Bbmatrix%7D%20%5Crightarrow%20%5Cbegin%7Bbmatrix%7D%200%20%26%200%20%26%202%20%26%200%5C%5C%200%20%26%201%20%26%200%20%26%200%5C%5C%200%20%26%200%20%26%200%20%26%200%5C%5C%203%20%26%200%20%26%200%20%26%204%20%5Cend%7Bbmatrix%7D)
* Transpose Convolution(deconvolution)
> Learnable upsampling, 

## Classification + Localization
> Image내에 object를 1개만 찾고 labling 하는 것
* 출력값을 2개 가짐. FC에서 Class scores(Softmax loss)와 Box Coordinates(L2 Norm loss)
* 두 loss를 Hyperparameter(가중치)로 결합하여 새로운 loss를 만들고 Hyperparameter를 tuning하여 성능 비교. 다만, Hyperparameter의 값에 따라서 loss의 속성 자체가 바뀔 수 있으므로 loss 수치로 모델의 성능을 비교하기는 어려움..??
* loss를 결합하여 한 번에 학습시키는 것이 아니라 Network를 Freeze 시키고(Transfer Learning처럼) FC만 Tuning하여 각 최적의 loss를 찾는 방법도 있음

## Object Detection
> 예측해야하는 Bbox의 갯수가 정해져 있지 않음. Localization과 달리 Input에 따라서 Bbox의 갯수가 달라짐

### 1) Sliding Window
> Localization과 마찬가지로 Input image를 매우 작은 영역으로 쪼개서 model simulation
* Window를 어떻게 추출해야할지가 문제. Window를 어떤 비율로 할지 등으로 인해 cost가 너무 큼

### 2) Region Proposals
> object가 있을법한 "blobby"한 image regions을 찾아냄. 전통적인 신호처리 방법(deep learning에서는 사용하지 않음)
> 


## Instance Segmentation
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE2OTgxNzMwNSwtODYzMzk1NTU3LC05Nj
g3MzQ5MjYsMTg2MjU0NDI2LC0zNjI4NjY1NjQsLTIwMjY3MjY4
NDksLTIxMDIzNzQ1NTMsLTE5MDU0MjgyMDUsLTI4NDA3NjU0LC
0yMTg3MDA0NTQsLTE2OTkwNjg0NTMsLTE0NjQwNjYwLC0xMzcy
Njk3Mzk4LC04Mzg3MjkzNDYsMTIxMDA4ODQ1Miw2NDI5MTk2OT
IsMTkyNDY4MDkzOCwyMDY3MTQyOTYwLDk5MjExMTQ5MywtNjQ2
NzU5NTddfQ==
-->